{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The data is cleaned up. There are no unqueal length sequences. And, there is no zero padding. So, you shouldn't use any `Masking` layer (like I mentioned in the lecture). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert as many cells as you need for data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heartbeat_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Target']\n",
    "x = data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 4, 0, 0, 0, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(train_x)\n",
    "test_x=np.array(test_x)\n",
    "train_x=train_x.astype(np.float32)\n",
    "test_x=test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.856 , 0.824 , 0.562 , ..., 0.227 , 0.243 , 0.23  ],\n",
       "       [1.    , 0.64  , 0.053 , ..., 0.966 , 0.735 , 0.106 ],\n",
       "       [1.    , 0.754 , 0.0673, ..., 0.219 , 0.226 , 0.229 ],\n",
       "       ...,\n",
       "       [0.507 , 0.311 , 0.    , ..., 0.129 , 0.119 , 0.133 ],\n",
       "       [0.942 , 0.918 , 0.74  , ..., 0.113 , 0.0988, 0.0819],\n",
       "       [0.872 , 0.864 , 0.791 , ..., 0.279 , 0.294 , 0.286 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.856 ],\n",
       "        [0.824 ],\n",
       "        [0.562 ],\n",
       "        ...,\n",
       "        [0.227 ],\n",
       "        [0.243 ],\n",
       "        [0.23  ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.64  ],\n",
       "        [0.053 ],\n",
       "        ...,\n",
       "        [0.966 ],\n",
       "        [0.735 ],\n",
       "        [0.106 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.754 ],\n",
       "        [0.0673],\n",
       "        ...,\n",
       "        [0.219 ],\n",
       "        [0.226 ],\n",
       "        [0.229 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.507 ],\n",
       "        [0.311 ],\n",
       "        [0.    ],\n",
       "        ...,\n",
       "        [0.129 ],\n",
       "        [0.119 ],\n",
       "        [0.133 ]],\n",
       "\n",
       "       [[0.942 ],\n",
       "        [0.918 ],\n",
       "        [0.74  ],\n",
       "        ...,\n",
       "        [0.113 ],\n",
       "        [0.0988],\n",
       "        [0.0819]],\n",
       "\n",
       "       [[0.872 ],\n",
       "        [0.864 ],\n",
       "        [0.791 ],\n",
       "        ...,\n",
       "        [0.279 ],\n",
       "        [0.294 ],\n",
       "        [0.286 ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.582035\n",
       "4    0.198995\n",
       "2    0.155402\n",
       "1    0.055905\n",
       "3    0.007663\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.6992 - accuracy: 0.7687 - val_loss: 0.5864 - val_accuracy: 0.8212\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8494 - val_loss: 0.4395 - val_accuracy: 0.8710\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8787 - val_loss: 0.3874 - val_accuracy: 0.8765\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8945 - val_loss: 0.3100 - val_accuracy: 0.9104\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.9009 - val_loss: 0.3212 - val_accuracy: 0.9133\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.9072 - val_loss: 0.2958 - val_accuracy: 0.9183\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.9083 - val_loss: 0.2839 - val_accuracy: 0.9204\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.9148 - val_loss: 0.2767 - val_accuracy: 0.9263\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2697 - accuracy: 0.9178 - val_loss: 0.2713 - val_accuracy: 0.9154\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.9207 - val_loss: 0.2708 - val_accuracy: 0.9196\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9232 - val_loss: 0.3928 - val_accuracy: 0.8668\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9239 - val_loss: 0.2663 - val_accuracy: 0.9250\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9219 - val_loss: 0.3312 - val_accuracy: 0.9070\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2280 - accuracy: 0.9345 - val_loss: 0.3667 - val_accuracy: 0.8681\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9255 - val_loss: 0.2590 - val_accuracy: 0.9271\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9314 - val_loss: 0.3121 - val_accuracy: 0.9024\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9341 - val_loss: 0.2379 - val_accuracy: 0.9322\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9313 - val_loss: 0.2867 - val_accuracy: 0.9196\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9314 - val_loss: 0.2337 - val_accuracy: 0.9380\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2051 - accuracy: 0.9365 - val_loss: 0.2256 - val_accuracy: 0.9430\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9395 - val_loss: 0.2228 - val_accuracy: 0.9368\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1966 - accuracy: 0.9377 - val_loss: 0.2608 - val_accuracy: 0.9250\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9417 - val_loss: 0.2492 - val_accuracy: 0.9384\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1874 - accuracy: 0.9392 - val_loss: 0.2617 - val_accuracy: 0.9313\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9397 - val_loss: 0.4032 - val_accuracy: 0.8593\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9417 - val_loss: 0.3040 - val_accuracy: 0.9008\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9383 - val_loss: 0.8077 - val_accuracy: 0.7031\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9392 - val_loss: 0.2442 - val_accuracy: 0.9372\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9458 - val_loss: 0.4426 - val_accuracy: 0.8224\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.9438 - val_loss: 0.2164 - val_accuracy: 0.9418\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9480 - val_loss: 0.2334 - val_accuracy: 0.9380\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9445 - val_loss: 0.3210 - val_accuracy: 0.8869\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1719 - accuracy: 0.9460 - val_loss: 0.2413 - val_accuracy: 0.9355\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9481 - val_loss: 0.2256 - val_accuracy: 0.9401\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1604 - accuracy: 0.9494 - val_loss: 0.2144 - val_accuracy: 0.9451\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9501 - val_loss: 1.4904 - val_accuracy: 0.5817\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9449 - val_loss: 0.2187 - val_accuracy: 0.9435\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9508 - val_loss: 0.2100 - val_accuracy: 0.9468\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1555 - accuracy: 0.9494 - val_loss: 0.2415 - val_accuracy: 0.9326\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9505 - val_loss: 0.2312 - val_accuracy: 0.9464\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9532 - val_loss: 0.2258 - val_accuracy: 0.9393\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1517 - accuracy: 0.9501 - val_loss: 0.2183 - val_accuracy: 0.9439\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9528 - val_loss: 0.2758 - val_accuracy: 0.9372\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9499 - val_loss: 0.2805 - val_accuracy: 0.9175\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9497 - val_loss: 0.2438 - val_accuracy: 0.9330\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9515 - val_loss: 0.2343 - val_accuracy: 0.9355\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9530 - val_loss: 0.2281 - val_accuracy: 0.9389\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9546 - val_loss: 0.3724 - val_accuracy: 0.8807\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.9523 - val_loss: 0.2813 - val_accuracy: 0.9242\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9526 - val_loss: 0.2668 - val_accuracy: 0.9292\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.26684197783470154, 0.9292294979095459]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.27\n",
      "accuracy: 92.92%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.6839 - accuracy: 0.7599 - val_loss: 0.4867 - val_accuracy: 0.8183\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8501 - val_loss: 0.4454 - val_accuracy: 0.8463\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8790 - val_loss: 0.4002 - val_accuracy: 0.8702\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8979 - val_loss: 0.2659 - val_accuracy: 0.9171\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.9020 - val_loss: 0.2788 - val_accuracy: 0.9221\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2796 - accuracy: 0.9078 - val_loss: 0.3169 - val_accuracy: 0.8874\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.9191 - val_loss: 0.2710 - val_accuracy: 0.9229\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.9266 - val_loss: 0.2490 - val_accuracy: 0.9301\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9293 - val_loss: 0.2539 - val_accuracy: 0.9284\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9307 - val_loss: 0.2515 - val_accuracy: 0.9296\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9307 - val_loss: 0.4591 - val_accuracy: 0.8572\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.9350 - val_loss: 0.2418 - val_accuracy: 0.9280\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1993 - accuracy: 0.9341 - val_loss: 0.2587 - val_accuracy: 0.9238\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9383 - val_loss: 1.1510 - val_accuracy: 0.6206\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9300 - val_loss: 0.2906 - val_accuracy: 0.9255\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2104 - accuracy: 0.9340 - val_loss: 0.4193 - val_accuracy: 0.8811\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9388 - val_loss: 0.2047 - val_accuracy: 0.9418\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9417 - val_loss: 0.4013 - val_accuracy: 0.8798\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2114 - accuracy: 0.9314 - val_loss: 0.2316 - val_accuracy: 0.9368\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1601 - accuracy: 0.9494 - val_loss: 0.2093 - val_accuracy: 0.9435\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9505 - val_loss: 0.2192 - val_accuracy: 0.9410\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9505 - val_loss: 0.8281 - val_accuracy: 0.7546\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9300 - val_loss: 0.2986 - val_accuracy: 0.9179\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9497 - val_loss: 0.2817 - val_accuracy: 0.9271\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9499 - val_loss: 0.5550 - val_accuracy: 0.8405\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9447 - val_loss: 0.3896 - val_accuracy: 0.8907\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9447 - val_loss: 0.2523 - val_accuracy: 0.9372\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9567 - val_loss: 0.4448 - val_accuracy: 0.8710\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9559 - val_loss: 0.2663 - val_accuracy: 0.9334\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9537 - val_loss: 0.2165 - val_accuracy: 0.9472\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9585 - val_loss: 0.2657 - val_accuracy: 0.9397\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9555 - val_loss: 0.3112 - val_accuracy: 0.9200\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9533 - val_loss: 0.2791 - val_accuracy: 0.9259\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9550 - val_loss: 0.2352 - val_accuracy: 0.9422\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9578 - val_loss: 0.2479 - val_accuracy: 0.9393\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9580 - val_loss: 0.2936 - val_accuracy: 0.9309\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9582 - val_loss: 0.2477 - val_accuracy: 0.9468\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9620 - val_loss: 0.2507 - val_accuracy: 0.9368\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.9634 - val_loss: 0.4626 - val_accuracy: 0.8681\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9587 - val_loss: 0.2149 - val_accuracy: 0.9456\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1203 - accuracy: 0.9600 - val_loss: 0.2451 - val_accuracy: 0.9451\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1207 - accuracy: 0.9593 - val_loss: 0.2695 - val_accuracy: 0.9376\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9596 - val_loss: 0.3083 - val_accuracy: 0.9296\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1172 - accuracy: 0.9621 - val_loss: 0.6660 - val_accuracy: 0.8074\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9449 - val_loss: 0.2720 - val_accuracy: 0.9481\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1416 - accuracy: 0.9539 - val_loss: 0.2524 - val_accuracy: 0.9397\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9636 - val_loss: 0.2583 - val_accuracy: 0.9422\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9648 - val_loss: 0.3028 - val_accuracy: 0.9296\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.9628 - val_loss: 0.3261 - val_accuracy: 0.9192\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9623 - val_loss: 0.5478 - val_accuracy: 0.8907\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2824445962905884, 0.908710241317749]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.28\n",
      "accuracy: 90.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(20, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 6s 24ms/step - loss: 1.1176 - accuracy: 0.5765 - val_loss: 1.1715 - val_accuracy: 0.5900\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 1.0660 - accuracy: 0.5876 - val_loss: 1.0731 - val_accuracy: 0.5892\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 1.0547 - accuracy: 0.5953 - val_loss: 0.9616 - val_accuracy: 0.6131\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.9178 - accuracy: 0.6554 - val_loss: 1.4403 - val_accuracy: 0.4824\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.7674 - accuracy: 0.7349 - val_loss: 1.4447 - val_accuracy: 0.4376\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.7908 - accuracy: 0.7340 - val_loss: 2.0000 - val_accuracy: 0.2818\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.7038 - accuracy: 0.7624 - val_loss: 0.5684 - val_accuracy: 0.8166\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.6222 - accuracy: 0.7972 - val_loss: 0.5692 - val_accuracy: 0.8237\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.6028 - accuracy: 0.8053 - val_loss: 0.6102 - val_accuracy: 0.7956\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.6384 - accuracy: 0.7949 - val_loss: 0.7237 - val_accuracy: 0.7642\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.6408 - accuracy: 0.7893 - val_loss: 0.6082 - val_accuracy: 0.7936\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5789 - accuracy: 0.8198 - val_loss: 0.5186 - val_accuracy: 0.8413\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5598 - accuracy: 0.8297 - val_loss: 0.4997 - val_accuracy: 0.8580\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5279 - accuracy: 0.8458 - val_loss: 0.5781 - val_accuracy: 0.8141\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5214 - accuracy: 0.8448 - val_loss: 0.4654 - val_accuracy: 0.8631\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5321 - accuracy: 0.8381 - val_loss: 0.5404 - val_accuracy: 0.8379\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.5291 - accuracy: 0.8344 - val_loss: 0.4633 - val_accuracy: 0.8639\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.5025 - accuracy: 0.8492 - val_loss: 0.5009 - val_accuracy: 0.8497\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5055 - accuracy: 0.8514 - val_loss: 0.5303 - val_accuracy: 0.8208\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.5029 - accuracy: 0.8523 - val_loss: 0.4561 - val_accuracy: 0.8714\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5477679967880249, 0.8907034993171692]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.55\n",
      "accuracy: 89.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(20),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 12s 53ms/step - loss: 1.1276 - accuracy: 0.5799 - val_loss: 1.0602 - val_accuracy: 0.6068\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 10s 57ms/step - loss: 1.0990 - accuracy: 0.5833 - val_loss: 1.0898 - val_accuracy: 0.5900\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 1.0174 - accuracy: 0.6071 - val_loss: 1.0847 - val_accuracy: 0.6106\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 9s 49ms/step - loss: 1.0106 - accuracy: 0.6019 - val_loss: 1.0166 - val_accuracy: 0.5900\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 1.0768 - accuracy: 0.5897 - val_loss: 1.0187 - val_accuracy: 0.6013\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.9993 - accuracy: 0.6145 - val_loss: 0.9677 - val_accuracy: 0.6382\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.9955 - accuracy: 0.6416 - val_loss: 0.9502 - val_accuracy: 0.6679\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.9160 - accuracy: 0.6554 - val_loss: 0.9192 - val_accuracy: 0.6533\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.8404 - accuracy: 0.6841 - val_loss: 0.8017 - val_accuracy: 0.7165\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 10s 59ms/step - loss: 0.7634 - accuracy: 0.7344 - val_loss: 0.6659 - val_accuracy: 0.7818\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 12s 68ms/step - loss: 0.6014 - accuracy: 0.8053 - val_loss: 0.5426 - val_accuracy: 0.8166\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 11s 61ms/step - loss: 0.8540 - accuracy: 0.7008 - val_loss: 0.7097 - val_accuracy: 0.7915\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 9s 54ms/step - loss: 0.6494 - accuracy: 0.7749 - val_loss: 0.6454 - val_accuracy: 0.7923\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.6476 - accuracy: 0.7740 - val_loss: 0.5839 - val_accuracy: 0.7952\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 12s 67ms/step - loss: 0.5421 - accuracy: 0.8119 - val_loss: 0.4675 - val_accuracy: 0.8413\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 11s 62ms/step - loss: 0.5068 - accuracy: 0.8263 - val_loss: 0.6026 - val_accuracy: 0.7965\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 9s 52ms/step - loss: 0.4771 - accuracy: 0.8381 - val_loss: 0.4257 - val_accuracy: 0.8719\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 10s 56ms/step - loss: 0.4350 - accuracy: 0.8629 - val_loss: 0.3924 - val_accuracy: 0.8731\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 9s 51ms/step - loss: 0.4108 - accuracy: 0.8699 - val_loss: 0.3890 - val_accuracy: 0.8752\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 9s 50ms/step - loss: 0.4104 - accuracy: 0.8658 - val_loss: 0.5145 - val_accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5145398378372192, 0.8094639778137207]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.51\n",
      "accuracy: 80.95%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='Softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 7s 30ms/step - loss: 1.1066 - accuracy: 0.5838 - val_loss: 1.1285 - val_accuracy: 0.5771\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 6s 36ms/step - loss: 0.9006 - accuracy: 0.6744 - val_loss: 0.6971 - val_accuracy: 0.7596\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.6233 - accuracy: 0.7929 - val_loss: 0.6020 - val_accuracy: 0.7864\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.4948 - accuracy: 0.8424 - val_loss: 0.4995 - val_accuracy: 0.8132\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.4266 - accuracy: 0.8632 - val_loss: 0.3933 - val_accuracy: 0.8790\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.4196 - accuracy: 0.8688 - val_loss: 0.4050 - val_accuracy: 0.8865\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 6s 34ms/step - loss: 0.3892 - accuracy: 0.8803 - val_loss: 0.3498 - val_accuracy: 0.8995\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 6s 31ms/step - loss: 0.3706 - accuracy: 0.8878 - val_loss: 0.3365 - val_accuracy: 0.9016\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.3519 - accuracy: 0.8902 - val_loss: 0.3566 - val_accuracy: 0.8920\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.3913 - accuracy: 0.8737 - val_loss: 0.3590 - val_accuracy: 0.8840\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 7s 39ms/step - loss: 0.3453 - accuracy: 0.8943 - val_loss: 0.3625 - val_accuracy: 0.8920\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.3422 - accuracy: 0.8923 - val_loss: 0.3485 - val_accuracy: 0.8953\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 0.4032 - accuracy: 0.8744 - val_loss: 0.3676 - val_accuracy: 0.8823\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3676387667655945, 0.8823283314704895]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.37\n",
      "accuracy: 88.23%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(20),\n",
    "    keras.layers.Dense(5, activation='Softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 7s 28ms/step - loss: 1.0858 - accuracy: 0.5903 - val_loss: 1.0594 - val_accuracy: 0.5842\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.8601 - accuracy: 0.6814 - val_loss: 0.7184 - val_accuracy: 0.7316\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.5442 - accuracy: 0.8232 - val_loss: 0.7250 - val_accuracy: 0.7295\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.4842 - accuracy: 0.8464 - val_loss: 0.3710 - val_accuracy: 0.8907\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.4029 - accuracy: 0.8746 - val_loss: 0.2989 - val_accuracy: 0.9125\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.3793 - accuracy: 0.8837 - val_loss: 0.3247 - val_accuracy: 0.9008\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.3191 - accuracy: 0.9011 - val_loss: 0.2941 - val_accuracy: 0.9091\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.3006 - accuracy: 0.9045 - val_loss: 0.3282 - val_accuracy: 0.8907\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.2856 - accuracy: 0.9119 - val_loss: 0.2834 - val_accuracy: 0.9167\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.3040 - accuracy: 0.9033 - val_loss: 0.2720 - val_accuracy: 0.9171\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.2771 - accuracy: 0.9130 - val_loss: 0.3137 - val_accuracy: 0.8920\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.2547 - accuracy: 0.9182 - val_loss: 0.2436 - val_accuracy: 0.9267\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.2427 - accuracy: 0.9248 - val_loss: 0.2984 - val_accuracy: 0.9133\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.2358 - accuracy: 0.9259 - val_loss: 0.7062 - val_accuracy: 0.7709\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.2312 - accuracy: 0.9261 - val_loss: 0.2233 - val_accuracy: 0.9376\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.2398 - accuracy: 0.9253 - val_loss: 0.4182 - val_accuracy: 0.8647\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.2373 - accuracy: 0.9244 - val_loss: 0.2290 - val_accuracy: 0.9296\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.2171 - accuracy: 0.9273 - val_loss: 0.2222 - val_accuracy: 0.9343\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 5s 26ms/step - loss: 0.2119 - accuracy: 0.9331 - val_loss: 0.2325 - val_accuracy: 0.9301\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 4s 26ms/step - loss: 0.2090 - accuracy: 0.9359 - val_loss: 0.2824 - val_accuracy: 0.9087\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2824445962905884, 0.908710241317749]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.28\n",
      "accuracy: 90.87%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Model-1:Cross-sectional Shallow Keras Model(with one layer)- Test Accuracy- 92.2%\n",
    "\n",
    "Model-2:Cross-sectional Deep keras Model(with two or more layers)- Test Accuracy-90.87%\n",
    "\n",
    "Model-3:Sequential Shallow LSTM Model(with one layer)- Test Accuracy-89.07%\n",
    "\n",
    "Model-4:Sequential Deep LSTM Model(with two layers)- Test Accuracy-80.95%\n",
    "\n",
    "Model-5:Sequential Shallow GRU Model(with only one layer)-Test Accuracy-88.23%\n",
    "\n",
    "Model-6:Sequential Deep GRU Model(with only two layers)-Test Accuracy-90.87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which model performs the best and why? (0.5 points) \n",
    "## How does it compare to baseline? (0.5 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross sectional Shallow Keras Model performs the best when compared to the remaining models. Its Test Accuracy is 92.2% which remains highest than all other test accuracies.\n",
    "\n",
    "Reason: 1.Number of neurons & hidden layers in shallow Keras Model with appropriate learning rate and Epochs helps the model to get the best test accuracy. \n",
    "\n",
    "Comparison with Baseline: 0.5825\n",
    "\n",
    "Cross sectional Shallow Keras Model has 92.2% test accuracy which is way larger value than 58.25%. Evidently we can conclude that it is a efficient Model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
